{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CUDA code_coursework_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOmR5+af8xfBL/cieF7/JxA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alyrazik/CUDA/blob/main/CUDA_code_coursework_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fjg6jWth5eeJ"
      },
      "source": [
        "!apt-get --purge remove cuda nvidia* libnvidia-*\r\n",
        "!dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\r\n",
        "!apt-get remove cuda-*\r\n",
        "!apt autoremove\r\n",
        "!apt-get update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY3ZqNzu5xVA"
      },
      "source": [
        "!wget https://developer.nvidia.com/compute/cuda/9.2/Prod/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64 -O cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\r\n",
        "!dpkg -i cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\r\n",
        "!apt-key add /var/cuda-repo-9-2-local/7fa2af80.pub\r\n",
        "!apt-get update\r\n",
        "!apt-get install cuda-9.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqtrkQNU54Jl"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dR1bK4n859fQ",
        "outputId": "381838cc-84a7-434a-8cd1-5a9908d52e0a"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-gv2f49xb\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-gv2f49xb\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp37-none-any.whl size=4307 sha256=4b28d51fd03664de5fcf91e1decfe4b2520061d4f1b7eb4fef2df20726724a43\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-craxws4s/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWOkly6G6CIn",
        "outputId": "2daa4843-054b-44a8-cd56-d3798faa7865"
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r-WGSOktm8p"
      },
      "source": [
        " %reload_ext nvcc_plugin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfaeCeuPzEBM"
      },
      "source": [
        "#HERE IT IS... THE FINAL PIECE OF CODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ8Nd9LuF1gu",
        "outputId": "b9d7e9fc-eb5d-469b-cf7c-482ba00cead3"
      },
      "source": [
        "%%cu \r\n",
        "#include <iostream> \r\n",
        "#include <stdlib.h>\r\n",
        "#include <cstdio>\r\n",
        "#include <cublas_v2.h>\r\n",
        "#include <cuda_runtime.h>\r\n",
        "#include <chrono>\r\n",
        "using namespace std; \r\n",
        "\r\n",
        "//#define N 10\r\n",
        "//#define M 10\r\n",
        "\r\n",
        "\r\n",
        "// __global__ means this function will be executed on the GPU and is callable from the host.\r\n",
        "// this version of the function parallizes the outer loop only.\r\n",
        "\r\n",
        "__global__ void GTensorsOperation(float* a, float* b, float* c, float* d, int n, int m)\r\n",
        "{\r\n",
        "\r\n",
        "  int i = threadIdx.x; // i is unique for each thread.\r\n",
        " \r\n",
        "if (i<n) \r\n",
        "// so we won't run into a problem in case the number of threads exceeded the...\r\n",
        "// array elements N. (we'll think of a better way to parllelize the second loop\r\n",
        "// as well and them make SIZE n*m\r\n",
        "   for (int j=0; j<m; j++) \r\n",
        "   {\r\n",
        "       d[i*m+j]=a[i]*b[j]+c[i*m+j];\r\n",
        "   }\r\n",
        "      \r\n",
        "} \r\n",
        "\r\n",
        "// __global__ means this function will be executed on the GPU and is callable from the host.\r\n",
        "// this version of the function parallizes the inner loop as well as the outer loop.\r\n",
        "\r\n",
        "__global__ void G2TensorsOperation(float* a, float* b, float* c, float* d, int n, int m)\r\n",
        "{\r\n",
        "\r\n",
        "  int i = threadIdx.x; // i is unique for each thread.\r\n",
        " \r\n",
        "if (i<n*m) \r\n",
        "// so we won't run into a problem in case the number of threads exceeded the...\r\n",
        "// array elements N*M. \r\n",
        "      //i/M counts one (increments) every M elements until it reaches the count of N.\r\n",
        "      //i%M counts M times (from 0 to M-1) and then repeats this series N times.\r\n",
        "      //this basically accomplishes the multiplication process between the two vectors\r\n",
        "      d[i]=a[i/m]*b[i%m]+c[i]; \r\n",
        "}\r\n",
        "// and the CPU implementation.\r\n",
        "\r\n",
        "void TensorsOperation(float* a, float* b, float* c, float* d, int n, int m)\r\n",
        "{\r\n",
        " for (int i=0; i<n; i++)\r\n",
        "   for (int j=0; j<m; j++) \r\n",
        "   {\r\n",
        "       d[i*m+j]=a[i]*b[j]+c[i*m+j];\r\n",
        "   }\r\n",
        "      \r\n",
        "}\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "int main() \r\n",
        "{ \r\n",
        "    \r\n",
        "// Generate a, b, c matrices with random elements using N and M\r\n",
        "// they will be used to initalize the variables for both CPU and GPU.\r\n",
        "cout<<\"N       M       GPU1        GPU(NxM)       CPU\"<<endl;\r\n",
        "int N;\r\n",
        "int M=10;\r\n",
        "for (N =10; N<=10000; N=10*N)\r\n",
        "{\r\n",
        "//cout<<\"\\nLooping with M=\"<<M<<\" and N=\"<<N<<endl;\r\n",
        "cout<<N<<\"\\t\"<<M<<\"\\t\";\r\n",
        "\r\n",
        "float* A = new float[N];\r\n",
        "float* B = new float[M];\r\n",
        "float* C = new float[N*M];\r\n",
        "\r\n",
        "for(int i=0;i<N;i++)\r\n",
        "      A[i]=rand()%100;\r\n",
        "for(int i=0;i<M;i++)\r\n",
        "      B[i]=rand()%100;\r\n",
        "for(int i=0;i<N*M;i++)\r\n",
        "      C[i]=rand()%100;\r\n",
        "\r\n",
        "\r\n",
        "//cout << \"This code runs the operation on GPU\\n\";\r\n",
        "int n=N;\r\n",
        "int m=M;\r\n",
        "\r\n",
        "float*a, *b, *c, *d;\r\n",
        "//allocate memory that is shared between the GPU device and the host CPU.\r\n",
        "cudaMallocManaged(&a, n*sizeof(float)); \r\n",
        "cudaMallocManaged(&b, m*sizeof(float));\r\n",
        "cudaMallocManaged(&c, n*m*sizeof(float));\r\n",
        "cudaMallocManaged(&d, n*m*sizeof(float));\r\n",
        "\r\n",
        "//initialize matrices\r\n",
        "for(int i=0;i<N;i++)\r\n",
        "      a[i]=A[i];\r\n",
        "for(int i=0;i<M;i++)\r\n",
        "      b[i]=B[i];\r\n",
        "for(int i=0;i<N*M;i++)\r\n",
        "      c[i]=C[i];\r\n",
        "\r\n",
        "//a[0]=1; a[1]=2; a[2]=3;\r\n",
        "//b[0]=4; b[1]=2;\r\n",
        "//c[0]=2; c[1]=1; c[2]=1; c[3]=2; c[4]=4; c[5]=5;\r\n",
        "\r\n",
        "\r\n",
        "//to calculate the time\r\n",
        "cudaEvent_t start, end;\r\n",
        "cudaEventCreate(&start); \r\n",
        "cudaEventCreate(&end); \r\n",
        "cudaEventRecord(start);\r\n",
        "\r\n",
        "//Kernel launch\r\n",
        " \r\n",
        "GTensorsOperation<<<1, N>>>(a, b, c, d, n, m); \r\n",
        "\r\n",
        "//1 is no. of thread blocks\r\n",
        "//3, the second p/m is the number of threads within each block. usually the number of elements in a vector, the number of iterations.\r\n",
        "\r\n",
        "cudaEventRecord(end); \r\n",
        "//get the CPU to wait for all kernels to finish.\r\n",
        "//cudaDeviceSynchronize(); //do I need it?\r\n",
        "cudaEventSynchronize(end);  \r\n",
        "\r\n",
        "float time = 0; \r\n",
        "cudaEventElapsedTime(&time, start, end);  \r\n",
        "//cout<<\"Time taken \"\r\n",
        "cout<<time<<\"    \";\r\n",
        "/*\r\n",
        "cout<<\"Result matrix D: \"<<endl;\r\n",
        "for (int i =0; i<n; i++)\r\n",
        " {\r\n",
        "  for (int j = 0; j<m; j++)\r\n",
        "    cout<<d[i*m+j]<<\" \";\r\n",
        "  cout<<endl;\r\n",
        " }\r\n",
        "*/\r\n",
        "\r\n",
        "//Try the next function  G2TensorsOperation<<<1, N>>>(a, b, c, d, n, m); \r\n",
        " \r\n",
        "//cout << \"\\nThis code runs the operation on GPU using N*M threads.\\n\";\r\n",
        "cudaEventRecord(start);\r\n",
        "G2TensorsOperation<<<1, N*M>>>(a, b, c, d, n, m); \r\n",
        "cudaEventRecord(end); \r\n",
        "cudaEventSynchronize(end); \r\n",
        "time = 0;\r\n",
        "cudaEventElapsedTime(&time, start, end);  \r\n",
        "// cudaEventElapsedTime computes elapsed time between two events (in milliseconds with a resolution of around 0.5 microseconds)\r\n",
        "// source: docs.nvidia.com\r\n",
        "//cout<<\"Time taken \"<<\r\n",
        "cout<<time<<\"    \";\r\n",
        " \r\n",
        "/*\r\n",
        "cout<<\"Result matrix D: \"<<endl;\r\n",
        "for (int i =0; i<n; i++)\r\n",
        " {\r\n",
        "  for (int j = 0; j<m; j++)\r\n",
        "    cout<<d[i*m+j]<<\" \";\r\n",
        "  cout<<endl;\r\n",
        " }\r\n",
        "*/\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "//free the allocated memory\r\n",
        "cudaFree(a);\r\n",
        "cudaFree(b);\r\n",
        "cudaFree(c);\r\n",
        "cudaFree(d);\r\n",
        "\r\n",
        "\r\n",
        "//now the CPU version:\r\n",
        "\r\n",
        "//cout << \"\\nThis code runs the operation on CPU\\n\";\r\n",
        "float* a1 = new float[n];\r\n",
        "float* b1 = new float[m];\r\n",
        "float* c1 = new float[n*m];\r\n",
        "float* d1 = new float[n*m];\r\n",
        "\r\n",
        "//initialize matrices\r\n",
        "for(int i=0;i<N;i++)\r\n",
        "      a1[i]=A[i];\r\n",
        "for(int i=0;i<M;i++)\r\n",
        "      b1[i]=B[i];\r\n",
        "for(int i=0;i<N*M;i++)\r\n",
        "      c1[i]=C[i];\r\n",
        "\r\n",
        "//calculate time\r\n",
        "using chrono::high_resolution_clock;\r\n",
        "using chrono::duration_cast;\r\n",
        "using chrono::duration;\r\n",
        "using chrono::milliseconds;\r\n",
        "auto t_start = high_resolution_clock::now();\r\n",
        "\r\n",
        " TensorsOperation(a1, b1, c1, d1, n, m);\r\n",
        "auto t_end = high_resolution_clock::now();\r\n",
        "\r\n",
        "duration<double, std::milli> ms_double = t_end - t_start;\r\n",
        "//cout << \"Time taken: \" \r\n",
        "cout<< ms_double.count() <<endl;\r\n",
        "\r\n",
        "/*\r\n",
        "cout<<\"Result matrix D: \\n\" ;\r\n",
        "for (int i =0; i<n; i++)\r\n",
        " {\r\n",
        "  for (int j = 0; j<m; j++)\r\n",
        "    cout<<d1[i*m+j]<<\" \";\r\n",
        "  cout<<endl;\r\n",
        " }\r\n",
        "*/\r\n",
        "//cout<<endl;\r\n",
        "M=M*10; \r\n",
        "\r\n",
        "\r\n",
        "}\r\n",
        "return 0; \r\n",
        "} \r\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N       M       GPU1        GPU(NxM)       CPU\n",
            "10\t10\t0.440704    0.012256    0.000713\n",
            "100\t100\t0.1992    0.002048    0.035488\n",
            "1000\t1000\t7.34189    0.002752    3.6769\n",
            "10000\t10000\t0.005472    0.002496    501.149\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}