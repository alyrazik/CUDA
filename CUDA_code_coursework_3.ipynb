{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CUDA code_coursework_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNTzne6V5JbWt4XTQB5bGnW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alyrazik/CUDA/blob/main/CUDA_code_coursework_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fjg6jWth5eeJ"
      },
      "source": [
        "!apt-get --purge remove cuda nvidia* libnvidia-*\r\n",
        "!dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\r\n",
        "!apt-get remove cuda-*\r\n",
        "!apt autoremove\r\n",
        "!apt-get update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY3ZqNzu5xVA"
      },
      "source": [
        "!wget https://developer.nvidia.com/compute/cuda/9.2/Prod/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64 -O cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\r\n",
        "!dpkg -i cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\r\n",
        "!apt-key add /var/cuda-repo-9-2-local/7fa2af80.pub\r\n",
        "!apt-get update\r\n",
        "!apt-get install cuda-9.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqtrkQNU54Jl",
        "outputId": "48902a59-324f-4fc1-d1ce-a30cfe47731e"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "Cuda compilation tools, release 11.0, V11.0.221\n",
            "Build cuda_11.0_bu.TC445_37.28845127_0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dR1bK4n859fQ",
        "outputId": "2fa33636-5f12-4a4c-a49b-436fb2b6b9b7"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-s19rx3b2\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-s19rx3b2\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp37-none-any.whl size=4307 sha256=bbd6a1c17f413e057155ce6507dcc398aa0a29865e478919538ac02079070354\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jxan__17/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWOkly6G6CIn",
        "outputId": "d9fa6b9e-6603-4707-e7cb-6bcf442b39c1"
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r-WGSOktm8p"
      },
      "source": [
        " %reload_ext nvcc_plugin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfaeCeuPzEBM"
      },
      "source": [
        "#Below code implements three functions; two implementation for the GPU and one for the CPU. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ8Nd9LuF1gu",
        "outputId": "503edbdf-aafc-4c3b-dff1-32eff2cfe68c"
      },
      "source": [
        "%%cu \r\n",
        "#include <iostream> \r\n",
        "#include <stdlib.h>\r\n",
        "#include <cstdio>\r\n",
        "#include <cublas_v2.h>\r\n",
        "#include <cuda_runtime.h>\r\n",
        "#include <chrono>\r\n",
        "#include <iomanip>\r\n",
        "using namespace std; \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "// __global__ means this function will be executed on the GPU and is callable from the host.\r\n",
        "// this version of the function parallizes the outer loop only.\r\n",
        "\r\n",
        "__global__ void GTensorsOperation(float* a, float* b, float* c, float* d, int n, int m)\r\n",
        "{\r\n",
        "\r\n",
        "  int i = threadIdx.x; // i is unique for each thread.\r\n",
        " \r\n",
        "if (i<n) \r\n",
        "// so we won't run into a problem in case the number of threads exceeded the...\r\n",
        "// array elements N. (we'll think of a better way to parllelize the second loop\r\n",
        "// as well and them make SIZE n*m\r\n",
        "   for (int j=0; j<m; j++) \r\n",
        "   {\r\n",
        "       d[i*m+j]=a[i]*b[j]+c[i*m+j];\r\n",
        "   }\r\n",
        "      \r\n",
        "} \r\n",
        "\r\n",
        "// __global__ means this function will be executed on the GPU and is callable from the host.\r\n",
        "// this version of the function parallizes the inner loop as well as the outer loop.\r\n",
        "\r\n",
        "__global__ void G2TensorsOperation(float* a, float* b, float* c, float* d, int n, int m)\r\n",
        "{\r\n",
        "\r\n",
        "  int i = threadIdx.x; // i is unique for each thread.\r\n",
        " \r\n",
        "if (i<n*m) \r\n",
        "// so we won't run into a problem in case the number of threads exceeded the...\r\n",
        "// array elements N*M. \r\n",
        "      //i/M counts one (increments) every M elements until it reaches the count of N.\r\n",
        "      //i%M counts M times (from 0 to M-1) and then repeats this series N times.\r\n",
        "      //this basically accomplishes the multiplication process between the two vectors\r\n",
        "      d[i]=a[i/m]*b[i%m]+c[i]; \r\n",
        "}\r\n",
        "// and the CPU implementation.\r\n",
        "\r\n",
        "void TensorsOperation(float* a, float* b, float* c, float* d, int n, int m)\r\n",
        "{\r\n",
        " for (int i=0; i<n; i++)\r\n",
        "   for (int j=0; j<m; j++) \r\n",
        "   {\r\n",
        "       d[i*m+j]=a[i]*b[j]+c[i*m+j];\r\n",
        "   }\r\n",
        "      \r\n",
        "}\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "int main() \r\n",
        "{ \r\n",
        "    \r\n",
        "// Generate a, b, c matrices with random elements using N and M\r\n",
        "// they will be used to initalize the variables for both CPU and GPU.\r\n",
        "cout<<\"N       M       GPU1    GPU(NxM)  CPU\"<<endl;\r\n",
        "int N;\r\n",
        "int M=10;\r\n",
        "for (N =10; N<=10000; N=10*N)\r\n",
        "{\r\n",
        "//cout<<\"\\nLooping with M=\"<<M<<\" and N=\"<<N<<endl;\r\n",
        "cout<<N<<\"\\t\"<<M<<\"\\t\";\r\n",
        "\r\n",
        "float* A = new float[N];\r\n",
        "float* B = new float[M];\r\n",
        "float* C = new float[N*M];\r\n",
        "\r\n",
        "for(int i=0;i<N;i++)\r\n",
        "      A[i]=rand()%100;\r\n",
        "for(int i=0;i<M;i++)\r\n",
        "      B[i]=rand()%100;\r\n",
        "for(int i=0;i<N*M;i++)\r\n",
        "      C[i]=rand()%100;\r\n",
        "\r\n",
        "\r\n",
        "//cout << \"This code runs the operation on GPU\\n\";\r\n",
        "int n=N;\r\n",
        "int m=M;\r\n",
        "\r\n",
        "float*a1, *b1, *c1, *d1;\r\n",
        "//allocate memory that is shared between the GPU device and the host CPU.\r\n",
        "cudaMallocManaged(&a1, n*sizeof(float)); \r\n",
        "cudaMallocManaged(&b1, m*sizeof(float));\r\n",
        "cudaMallocManaged(&c1, n*m*sizeof(float));\r\n",
        "cudaMallocManaged(&d1, n*m*sizeof(float));\r\n",
        "\r\n",
        "//initialize matrices\r\n",
        "for(int i=0;i<N;i++)\r\n",
        "      a1[i]=A[i];\r\n",
        "for(int i=0;i<M;i++)\r\n",
        "      b1[i]=B[i];\r\n",
        "for(int i=0;i<N*M;i++)\r\n",
        "      c1[i]=C[i];\r\n",
        "\r\n",
        "\r\n",
        "//to calculate the time\r\n",
        "cudaEvent_t start, end;\r\n",
        "cudaEventCreate(&start); \r\n",
        "cudaEventCreate(&end); \r\n",
        "cudaEventRecord(start);\r\n",
        "\r\n",
        "//Kernel launch\r\n",
        " \r\n",
        "GTensorsOperation<<<1, N>>>(a1, b1, c1, d1, n, m); \r\n",
        "\r\n",
        "//1 is no. of thread blocks\r\n",
        "//3, the second p/m is the number of threads within each block. usually the number of elements in a vector, the number of iterations.\r\n",
        "\r\n",
        "cudaEventRecord(end); \r\n",
        "//get the CPU to wait for all kernels to finish.\r\n",
        "//cudaDeviceSynchronize(); //do I need it?\r\n",
        "cudaEventSynchronize(end);  \r\n",
        "\r\n",
        "float time = 0; \r\n",
        "cudaEventElapsedTime(&time, start, end);  \r\n",
        "//cout<<\"Time taken \"\r\n",
        "cout<<setprecision(2)<<time<<\"\\t\";//\"    \";\r\n",
        "\r\n",
        "\r\n",
        "//Try the next function  G2TensorsOperation<<<1, N>>>(a, b, c, d, n, m); \r\n",
        " \r\n",
        "//cout << \"\\nThis code runs the operation on GPU using N*M threads.\\n\";\r\n",
        "cudaEventRecord(start);\r\n",
        "G2TensorsOperation<<<1, N*M>>>(a1, b1, c1, d1, n, m); \r\n",
        "cudaEventRecord(end); \r\n",
        "cudaEventSynchronize(end); \r\n",
        "time = 0;\r\n",
        "cudaEventElapsedTime(&time, start, end);  \r\n",
        "// cudaEventElapsedTime computes elapsed time between two events (in milliseconds with a resolution of around 0.5 microseconds)\r\n",
        "// source: docs.nvidia.com\r\n",
        "//cout<<\"Time taken \"<<\r\n",
        "cout<<setprecision(2)<<time<<\"\\t  \";//\"    \";\r\n",
        " \r\n",
        "\r\n",
        "//free the allocated memory\r\n",
        "cudaFree(a1);\r\n",
        "cudaFree(b1);\r\n",
        "cudaFree(c1);\r\n",
        "cudaFree(d1);\r\n",
        "\r\n",
        "\r\n",
        "//now the CPU version:\r\n",
        "\r\n",
        "//cout << \"\\nThis code runs the operation on CPU\\n\";\r\n",
        "float* a = new float[n];\r\n",
        "float* b = new float[m];\r\n",
        "float* c = new float[n*m];\r\n",
        "float* d = new float[n*m];\r\n",
        "\r\n",
        "//initialize matrices\r\n",
        "for(int i=0;i<N;i++)\r\n",
        "      a[i]=A[i];\r\n",
        "for(int i=0;i<M;i++)\r\n",
        "      b[i]=B[i];\r\n",
        "for(int i=0;i<N*M;i++)\r\n",
        "      c[i]=C[i];\r\n",
        "\r\n",
        "//calculate time\r\n",
        "using chrono::high_resolution_clock;\r\n",
        "using chrono::duration_cast;\r\n",
        "using chrono::duration;\r\n",
        "using chrono::milliseconds;\r\n",
        "auto t_start = high_resolution_clock::now();\r\n",
        "\r\n",
        " TensorsOperation(a, b, c, d, n, m);\r\n",
        "auto t_end = high_resolution_clock::now();\r\n",
        "\r\n",
        "duration<double, std::milli> ms_double = t_end - t_start;\r\n",
        "//cout << \"Time taken: \" \r\n",
        "cout<<setprecision(4)<< ms_double.count() <<endl;\r\n",
        "\r\n",
        "/*\r\n",
        "cout<<\"Result matrix D: \\n\" ;\r\n",
        "for (int i =0; i<n; i++)\r\n",
        " {\r\n",
        "  for (int j = 0; j<m; j++)\r\n",
        "    cout<<d[i*m+j]<<\" \";\r\n",
        "  cout<<endl;\r\n",
        " }\r\n",
        "*/\r\n",
        "//cout<<endl;\r\n",
        "M=M*10; \r\n",
        "\r\n",
        "delete a, b, c, d;\r\n",
        "\r\n",
        "}\r\n",
        "\r\n",
        "\r\n",
        "return 0; \r\n",
        "} \r\n"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N       M       GPU1    GPU(NxM)  CPU\n",
            "10\t10\t0.18\t0.0093\t  0.000678\n",
            "100\t100\t0.23\t0.0023\t  0.04686\n",
            "1000\t1000\t4.5\t0.003\t  3.763\n",
            "10000\t10000\t0.0038\t0.0024\t  489.5\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0r981gCj_N9"
      },
      "source": [
        "#Below code displays the contents of d matrix to investigate accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgqZZKAajwhv",
        "outputId": "e3e3e0ea-352e-4543-fbea-59582a4916e8"
      },
      "source": [
        "%%cu \r\n",
        "#include <iostream> \r\n",
        "#include <stdlib.h>\r\n",
        "#include <cstdio>\r\n",
        "#include <cublas_v2.h>\r\n",
        "#include <cuda_runtime.h>\r\n",
        "#include <chrono>\r\n",
        "#include <iomanip>\r\n",
        "using namespace std; \r\n",
        "\r\n",
        "#define N 1000\r\n",
        "#define M 1000\r\n",
        "\r\n",
        "\r\n",
        "// __global__ means this function will be executed on the GPU and is callable from the host.\r\n",
        "// this version of the function parallizes the outer loop only.\r\n",
        "\r\n",
        "__global__ void GTensorsOperation(float* a, float* b, float* c, float* d, int n, int m)\r\n",
        "{\r\n",
        "\r\n",
        "  int i = threadIdx.x; // i is unique for each thread.\r\n",
        " \r\n",
        "if (i<N) \r\n",
        "// so we won't run into a problem in case the number of threads exceeded the...\r\n",
        "// array elements N. (we'll think of a better way to parllelize the second loop\r\n",
        "// as well and them make SIZE n*m\r\n",
        "   for (int j=0; j<m; j++) \r\n",
        "   {\r\n",
        "       d[i*m+j]=a[i]*b[j]+c[i*m+j];\r\n",
        "   }\r\n",
        "      \r\n",
        "} \r\n",
        "\r\n",
        "// __global__ means this function will be executed on the GPU and is callable from the host.\r\n",
        "// this version of the function parallizes the inner loop as well as the outer loop.\r\n",
        "\r\n",
        "__global__ void G2TensorsOperation(float* a, float* b, float* c, float* d, int n, int m)\r\n",
        "{\r\n",
        "\r\n",
        "  int i = threadIdx.x; // i is unique for each thread.\r\n",
        " \r\n",
        "if (i<N*M) \r\n",
        "// so we won't run into a problem in case the number of threads exceeded the...\r\n",
        "// array elements N*M. \r\n",
        "      //i/M counts one (increments) every M elements until it reaches the count of N.\r\n",
        "      //i%M counts M times (from 0 to M-1) and then repeats this series N times.\r\n",
        "      //this basically accomplishes the multiplication process between the two vectors\r\n",
        "      d[i]=a[i/M]*b[i%M]+c[i]; \r\n",
        "}\r\n",
        "// and the CPU implementation.\r\n",
        "\r\n",
        "void TensorsOperation(float* a, float* b, float* c, float* d, int n, int m)\r\n",
        "{\r\n",
        " for (int i=0; i<n; i++)\r\n",
        "   for (int j=0; j<m; j++) \r\n",
        "   {\r\n",
        "       d[i*m+j]=a[i]*b[j]+c[i*m+j];\r\n",
        "   }\r\n",
        "      \r\n",
        "}\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "int main() \r\n",
        "{ \r\n",
        "    \r\n",
        "// Generate a, b, c matrices with random elements using N and M\r\n",
        "// they will be used to initalize the variables for both CPU and GPU.\r\n",
        "\r\n",
        "float* A = new float[N];\r\n",
        "float* B = new float[M];\r\n",
        "float* C = new float[N*M];\r\n",
        "\r\n",
        "for(int i=0;i<N;i++)\r\n",
        "      A[i]=rand()%10/1000000000.0f;\r\n",
        "for(int i=0;i<M;i++)\r\n",
        "      B[i]=rand()%10/1000000000.0f;\r\n",
        "for(int i=0;i<N*M;i++)\r\n",
        "      C[i]=rand()%10/1000000000.0f; //10000000.0f;\r\n",
        "\r\n",
        "\r\n",
        "// Running first function on GPU\r\n",
        "cout << \"This code runs the operation on GPU\\n\";\r\n",
        "int n=N;\r\n",
        "int m=M;\r\n",
        "\r\n",
        "float*a1, *b1, *c1, *d1;\r\n",
        "//allocate memory that is shared between the GPU device and the host CPU.\r\n",
        "cudaMallocManaged(&a1, n*sizeof(float)); \r\n",
        "cudaMallocManaged(&b1, m*sizeof(float));\r\n",
        "cudaMallocManaged(&c1, n*m*sizeof(float));\r\n",
        "cudaMallocManaged(&d1, n*m*sizeof(float));\r\n",
        "\r\n",
        "//initialize matrices\r\n",
        "for(int i=0;i<N;i++)\r\n",
        "      a1[i]=A[i];\r\n",
        "for(int i=0;i<M;i++)\r\n",
        "      b1[i]=B[i];\r\n",
        "for(int i=0;i<N*M;i++)\r\n",
        "      c1[i]=C[i];\r\n",
        "\r\n",
        "//to calculate the time\r\n",
        "cudaEvent_t start, end;\r\n",
        "cudaEventCreate(&start); \r\n",
        "cudaEventCreate(&end); \r\n",
        " \r\n",
        "cudaEventRecord(start);\r\n",
        "\r\n",
        "//Kernel launch\r\n",
        " \r\n",
        "GTensorsOperation<<<1, N>>>(a1, b1, c1, d1, n, m); \r\n",
        "\r\n",
        "//1 is no. of thread blocks\r\n",
        "//3, the second p/m is the number of threads within each block. usually the number of elements in a vector, the number of iterations.\r\n",
        "\r\n",
        "cudaEventRecord(end); \r\n",
        " \r\n",
        "//get the CPU to wait for all kernels to finish.\r\n",
        "//cudaDeviceSynchronize(); //do I need it?\r\n",
        "cudaEventSynchronize(end);  \r\n",
        "\r\n",
        "float time = 0; \r\n",
        "cudaEventElapsedTime(&time, start, end);  \r\n",
        "cout<<\"Time taken \"<<time<<endl;\r\n",
        "if(N<11)\r\n",
        "{\r\n",
        "cout<<\"Result matrix D: \"<<endl;\r\n",
        "for (int i =0; i<n; i++)\r\n",
        " {\r\n",
        "  for (int j = 0; j<m; j++)\r\n",
        "    cout<<setprecision(15)<<d1[i*m+j]<<\"\\t\";\r\n",
        "  cout<<endl;\r\n",
        " }\r\n",
        "}\r\n",
        " \r\n",
        "\r\n",
        "\r\n",
        "///*\r\n",
        "//Try the next function  G2TensorsOperation<<<1, N>>>(a, b, c, d, n, m); \r\n",
        "float*a2, *b2, *c2, *d2;\r\n",
        "//allocate memory that is shared between the GPU device and the host CPU.\r\n",
        "cudaMallocManaged(&a2, n*sizeof(float)); \r\n",
        "cudaMallocManaged(&b2, m*sizeof(float));\r\n",
        "cudaMallocManaged(&c2, n*m*sizeof(float));\r\n",
        "cudaMallocManaged(&d2, n*m*sizeof(float));\r\n",
        "\r\n",
        "//initialize matrices\r\n",
        "for(int i=0;i<N;i++)\r\n",
        "      a2[i]=A[i];\r\n",
        "for(int i=0;i<M;i++)\r\n",
        "      b2[i]=B[i];\r\n",
        "for(int i=0;i<N*M;i++)\r\n",
        "      c2[i]=C[i];\r\n",
        "\r\n",
        "cout << \"\\nThis code runs the operation on GPU using N*M threads.\\n\";\r\n",
        "cudaEventRecord(start);\r\n",
        "G2TensorsOperation<<<1, N*M>>>(a2, b2, c2, d2, n, m); \r\n",
        "cudaEventRecord(end); \r\n",
        "cudaEventSynchronize(end); \r\n",
        "time = 0;\r\n",
        "cudaEventElapsedTime(&time, start, end);  \r\n",
        " \r\n",
        "// cudaEventElapsedTime computes elapsed time between two events (in milliseconds with a resolution of around 0.5 microseconds)\r\n",
        "// source: docs.nvidia.com\r\n",
        " \r\n",
        "cout<<\"Time taken \"<<time<<endl;\r\n",
        " \r\n",
        "if(N<11)\r\n",
        "{\r\n",
        "cout<<\"Result matrix D: \"<<endl;\r\n",
        "for (int i =0; i<n; i++)\r\n",
        " {\r\n",
        "  for (int j = 0; j<m; j++)\r\n",
        "    cout<<setprecision(15)<<d2[i*m+j]<<\"\\t\";\r\n",
        "  cout<<endl;\r\n",
        " }\r\n",
        "}\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "//now the CPU version:\r\n",
        "\r\n",
        "cout << \"\\nThis code runs the operation on CPU\\n\";\r\n",
        "float* a = new float[n];\r\n",
        "float* b = new float[m];\r\n",
        "float* c = new float[n*m];\r\n",
        "float* d = new float[n*m];\r\n",
        "\r\n",
        "//initialize matrices\r\n",
        "for(int i=0;i<N;i++)\r\n",
        "      a[i]=A[i];\r\n",
        "for(int i=0;i<M;i++)\r\n",
        "      b[i]=B[i];\r\n",
        "for(int i=0;i<N*M;i++)\r\n",
        "      c[i]=C[i];\r\n",
        "\r\n",
        "//calculate time\r\n",
        "using chrono::high_resolution_clock;\r\n",
        "using chrono::duration_cast;\r\n",
        "using chrono::duration;\r\n",
        "using chrono::milliseconds;\r\n",
        "auto t_start = high_resolution_clock::now();\r\n",
        "TensorsOperation(a, b, c, d, n, m);\r\n",
        "auto t_end = high_resolution_clock::now();\r\n",
        "\r\n",
        "duration<double, std::milli> ms_double = t_end - t_start;\r\n",
        "cout << \"Time taken: \" << ms_double.count() << \"ms\"<<endl;\r\n",
        "\r\n",
        "if(N<11)\r\n",
        "{\r\n",
        "cout<<\"Result matrix D: \\n\" ;\r\n",
        "for (int i =0; i<n; i++)\r\n",
        " {\r\n",
        "  for (int j = 0; j<m; j++)\r\n",
        "    cout<<setprecision(15)<<d[i*m+j]<<\"\\t\";\r\n",
        "  cout<<endl;\r\n",
        " }\r\n",
        "}\r\n",
        " \r\n",
        "cout<<\"\\nError between CPU and GPU \\n\" ;\r\n",
        "double error =0.0;\r\n",
        "for (int i =0; i<n; i++)\r\n",
        " {\r\n",
        "  for (int j = 0; j<m; j++)\r\n",
        "    //cout<<(d[i*m+j])<<\" \";\r\n",
        "    //printf(\"%.9lg \", d[i*m+j]);\r\n",
        "    error+=abs(d[i*m+j]-d2[i*m+j]);\r\n",
        " }\r\n",
        " cout<<setprecision(15)<<error<<endl;\r\n",
        "\r\n",
        "//free the allocated memory\r\n",
        "cudaFree(a1);\r\n",
        "cudaFree(b1);\r\n",
        "cudaFree(c1);\r\n",
        "cudaFree(d1);\r\n",
        "cudaFree(a2);\r\n",
        "cudaFree(b2);\r\n",
        "cudaFree(c2);\r\n",
        "cudaFree(d2);\r\n",
        "delete a, b, c, d;\r\n",
        " \r\n",
        "return 0; \r\n",
        "} \r\n"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This code runs the operation on GPU\n",
            "Time taken 4.48115\n",
            "\n",
            "This code runs the operation on GPU using N*M threads.\n",
            "Time taken 0.002624\n",
            "\n",
            "This code runs the operation on CPU\n",
            "Time taken: 3.62443ms\n",
            "\n",
            "Error between CPU and GPU \n",
            "0.00450293696432537\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20WdJy9hWfHW"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30oIBdGsXUBa",
        "outputId": "fc7dfbd8-0466-474f-e0cc-d56915c4a934"
      },
      "source": [
        "// this code runs math functions on both CPU and GPU to evidently compare accuracies. \r\n",
        "%%cu \r\n",
        "#include <cuda.h>\r\n",
        "#include <stdio.h>\r\n",
        "#include <iomanip>\r\n",
        "#include <iostream>\r\n",
        "using namespace std;\r\n",
        "\r\n",
        "__global__ void calcGPU() {\r\n",
        "\tfloat x = 0.000001f;\r\n",
        "\tfloat y = expf(x);\r\n",
        "\tprintf(\"GPU: %.9lg\\n\", y);\r\n",
        "  //cout<<setprecision(15)<<y;\r\n",
        "}\r\n",
        "\r\n",
        "void calcCPU() {\r\n",
        "\tfloat x = 0.000001f;\r\n",
        "\tfloat y = expf(x);\r\n",
        "\t//printf(\"CPU: %.9lg\\n\", y);\r\n",
        "  cout<<setprecision(15)<<y;\r\n",
        "}\r\n",
        "\r\n",
        "int main() {\r\n",
        "\r\n",
        "\tcalcGPU<<<1, 1>>>();\r\n",
        "\tcudaDeviceReset();\r\n",
        "\tcalcCPU();\r\n",
        "\treturn 0;\r\n",
        "}"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU: 1.00000107\n",
            "1.00000095367432\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_kXcjy8XdqL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}